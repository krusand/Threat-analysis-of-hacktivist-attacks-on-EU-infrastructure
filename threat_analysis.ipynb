{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import re\n",
    "import data_utils as du"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Demographic areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the onto-notes tag since the `MISC` tag of the regular tags is too general. We are interested in the `GPE` and `NORP` tags of the onto-notes tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_ids</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>OSINT</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cyberknow20</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>pro-Russian</td>\n",
       "      <td>NORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Today</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Poland</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   message_ids         text   label\n",
       "0            1        OSINT     ORG\n",
       "1            1  Cyberknow20  PERSON\n",
       "2            1  pro-Russian    NORP\n",
       "3            2        Today    DATE\n",
       "4            2       Poland     GPE"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the onto-notes tags\n",
    "ner_onto_df = pd.read_parquet(\"data/ner_tagged_data_onto.parquet\")\n",
    "ner_onto_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Austria', 'Belgium', 'Croatia', 'Cyprus', 'Czech republic', 'Denmark', 'Estonia', 'Finland', 'France', 'Germany', 'Greece', 'Hungary', 'Iceland', 'Ireland', 'Italy', 'Latvia', 'Lithuania', 'Luxembourg', 'Malta', 'Netherlands', 'Norway', 'Poland', 'Portugal', 'Romania', 'Slovakia', 'Slovenia', 'Spain', 'Sweden']\n",
      "28 out of 28 EU and Nordic countries have been targeted\n",
      "This corresponds to 100.0% of all the EU and Nordic countries\n"
     ]
    }
   ],
   "source": [
    "# filtering out all the GPE and NORP tags \n",
    "tags_of_interest = [\"GPE\", \"NORP\"]\n",
    "tag_mask = ner_onto_df['label'].isin(tags_of_interest)\n",
    "filtered_df = ner_onto_df[tag_mask]\n",
    "\n",
    "# selecting the text column of the filtered df\n",
    "text_set = set(filtered_df[\"text\"])\n",
    "\n",
    "# lower-casing all the elements of the set\n",
    "lowercase_set = {word.lower() for word in text_set}\n",
    "\n",
    "# retrieving the countries that are contained within the defined set of countries \n",
    "attacked_countries = [word for word in lowercase_set if word in eu_nordic_countries]\n",
    "\n",
    "# turning the countries into capital case \n",
    "capital_case_countries = [country.capitalize() for country in attacked_countries]\n",
    "\n",
    "# printing the resulting list of countries in alphabetical order\n",
    "print(sorted(capital_case_countries))\n",
    "\n",
    "# some quick summary statistics\n",
    "total_countries = len(eu_nordic_countries)\n",
    "number_attacked = len(attacked_countries)\n",
    "perc_attacked = round(number_attacked / total_countries * 100, 2)\n",
    "print(f\"{number_attacked} out of {total_countries} EU and Nordic countries have been targeted\")\n",
    "print(f\"This corresponds to {perc_attacked}% of all the EU and Nordic countries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Infrastructure sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'energy': 28,\n",
       " 'transport': 69,\n",
       " 'banking': 106,\n",
       " 'financial market infrastructure': 7,\n",
       " 'health': 0,\n",
       " 'drinking water': 0,\n",
       " 'waste water': 0,\n",
       " 'digital infrastructure': 9,\n",
       " 'public administration': 15,\n",
       " 'space': 4,\n",
       " 'food': 4,\n",
       " 'Unknown': 1826}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering out all the GPE and NORP tags \n",
    "tags_of_interest = [\"ORG\"]\n",
    "tag_mask = ner_onto_df['label'].isin(tags_of_interest)\n",
    "filtered_df = ner_onto_df[tag_mask]\n",
    "\n",
    "# selecting the text column of the filtered df\n",
    "text_set = set(filtered_df[\"text\"])\n",
    "\n",
    "# function to categorize organization\n",
    "def categorize_organization(name):\n",
    "    for sector, pattern in du.sectors_patterns.items():\n",
    "        if re.search(pattern, name, re.IGNORECASE):\n",
    "            return sector\n",
    "    return 'Unknown'\n",
    "\n",
    "# dictionary to keep track of counts\n",
    "sector_counts = {sector: 0 for sector in du.sectors_patterns.keys()}\n",
    "sector_counts[\"Unknown\"] = 0\n",
    "\n",
    "# assigning organizations to a sector\n",
    "for org in text_set:\n",
    "    sector = categorize_organization(org)\n",
    "    sector_counts[sector] += 1\n",
    "\n",
    "sector_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Security properties (CIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/hacktivist_messages.csv\", sep=\";\")\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# df[[\"Text\"]].sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary ~: 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m❌https:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/check-host\u001b[39m\u001b[38;5;124m'\u001b[39m, re\u001b[38;5;241m.\u001b[39mUNICODE)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Filter rows where 'text' column contains the pattern\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mText\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(filtered_df)\n",
      "File \u001b[1;32mc:\\Users\\sebas\\.conda\\envs\\LSDA\\Lib\\site-packages\\pandas\\core\\generic.py:1570\u001b[0m, in \u001b[0;36mNDFrame.__invert__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize:\n\u001b[0;32m   1567\u001b[0m     \u001b[38;5;66;03m# inv fails with 0 len\u001b[39;00m\n\u001b[0;32m   1568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1570\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__invert__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sebas\\.conda\\envs\\LSDA\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:361\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m             kwargs[k] \u001b[38;5;241m=\u001b[39m obj[b\u001b[38;5;241m.\u001b[39mmgr_locs\u001b[38;5;241m.\u001b[39mindexer]\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(f):\n\u001b[1;32m--> 361\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    363\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sebas\\.conda\\envs\\LSDA\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:393\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "\u001b[1;31mTypeError\u001b[0m: bad operand type for unary ~: 'float'"
     ]
    }
   ],
   "source": [
    "# Regular expression pattern to match\n",
    "pattern = re.compile(r'❌https:\\/\\/check-host', re.UNICODE)\n",
    "\n",
    "# Filter rows where 'text' column contains the pattern\n",
    "filtered_df = df[~df['Text'].str.contains(pattern, regex=True)]\n",
    "\n",
    "print(filtered_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
